{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 목차\n",
        "* 데이터 전처리\n",
        "* 딥러닝 모델 설계 및 훈련\n",
        "* 딥러닝 평가하기\n",
        "* 회고\n",
        "* Reference\n",
        "\n",
        "------------------\n",
        "루브릭\n",
        "\n",
        "아래의 기준을 바탕으로 프로젝트를 평가합니다.\n",
        "\n",
        "* 평가문항\t상세기준\n",
        "1. 데이터의 전처리 및 구성과정이 체계적으로 진행되었는가?\n",
        "\n",
        "  > 특수문자 제거, 토크나이저 생성, 패딩 처리의 작업들이 빠짐없이 진행되었는가?\n",
        "\n",
        "2. 가사 텍스트 생성 모델이 정상적으로 동작하는가?\n",
        "\n",
        "  > 텍스트 제너레이션 결과로 생성된 문장이 해석 가능한 문장인가?\n",
        "\n",
        "3. 텍스트 생성모델이 안정적으로 학습되었는가?\n",
        "\n",
        "  > 텍스트 생성모델의 validation loss가 2.2 이하로 낮아졌는가?"
      ],
      "metadata": {
        "id": "RUGZeoz0porR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Czel4y1po9H8",
        "outputId": "dc040996-4253-438e-a07e-e07f1db613d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "import glob  #glob 모듈의 glob 함수는 사용자가 제시한 조건에 맞는 파일명을 리스트 형식으로 반환한다\n",
        "import tensorflow\n",
        "\n",
        "print(tensorflow.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 전처리"
      ],
      "metadata": {
        "id": "GpNCHZ6e0DrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 불러오기"
      ],
      "metadata": {
        "id": "gUbwO4cD0YfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "txt_file_path = '/content/drive/MyDrive/아이펠 데이터/exp6 NLP/lyrics/*' \n",
        "txt_list = glob.glob(txt_file_path) #txt_file_path 경로에 있는 모든 파일명을 리스트 형식으로 txt_list 에 할당\n",
        "\n",
        "raw_corpus = [] \n",
        "\n",
        "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines() #read() : 파일 전체의 내용을 하나의 문자열로 읽어온다. , splitlines()  : 여러라인으로 구분되어 있는 문자열을 한라인씩 분리하여 리스트로 반환\n",
        "        raw_corpus.extend(raw) # extend() : 리스트함수로 추가적인 내용을 연장 한다.\n",
        "\n",
        "print(\"데이터 크기:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LztyHoZyGye",
        "outputId": "2e8ad603-084c-4795-edfb-2560c2889bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "데이터 크기: 187088\n",
            "Examples:\n",
            " [\"Let's stay together I, I'm I'm so in love with you\", 'Whatever you want to do', 'Is all right with me']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 정제\n",
        "\n",
        "* *지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거합니다. 너무 긴 문장은 노래 가사 작사하기에 어울리지 않을 수도 있겠죠.\n",
        "그래서 이번에는 문장을 토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외하기 를 권합니다.*"
      ],
      "metadata": {
        "id": "cnGVw5ku0PjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# re: Regular Expression의 줄임말로, 파이썬 정규표현식을 사용하기 위한 모듈\n",
        "\n",
        "import re \n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "nL0Q0eU_yGwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "불러온 문장들을 딥러닝에 적용하기에 좋게 정제하는 과정을 가진다. 우선 대문자를 소문자로 바꾸고 일부 특수문자를 제거한다. 그리고 문장의 시작과 끝을 알리는 토큰을 추가한다.\n",
        "\n",
        "이렇게 정제된 데이터에는 매우 많은 문장이 있으나 그 중 일부는 우리가 사용하기에 적합하지 않다. 예를 들어 빈 공백만이 존재하거나 극에서 ' : ' 만으로 이루어진 문장들이 그렇다. 따라서 이들을 제외한다. 또한 이번에는 가사를 만들고자 하므로 토큰의 개수가 15개 이상인 문장을 제외한다. 그런 긴 문장은 우리의 목적에 부합한 결과물을 만드는데 오히려 방해될 가능성이 높기 때문이다."
      ],
      "metadata": {
        "id": "BOqEYqPTmWKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 입력된 문장을\n",
        "#     1. 소문자로 바꾸고, 양쪽 공백을 지웁니다\n",
        "#     2. 특수문자 양쪽에 공백을 넣고\n",
        "#     3. 여러개의 공백은 하나의 공백으로 바꿉니다\n",
        "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿉니다\n",
        "#     5. 다시 양쪽 공백을 지웁니다\n",
        "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가합니다\n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 1\n",
        "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
        "    sentence = sentence.strip() # 5\n",
        "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "3J4kulmCyGs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 여기에 정제된 문장을 모을겁니다\n",
        "corpus = []\n",
        "\n",
        "# raw_corpus list에 저장된 문장들을 순서대로 반환하여 sentence에 저장\n",
        "for sentence in raw_corpus:\n",
        "    # 우리가 원하지 않는 문장은 건너뜁니다\n",
        "    if len(sentence) > 15: continue \n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    # 앞서 구현한 preprocess_sentence() 함수를 이용하여 문장을 정제를 하고 담아주세요\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "        \n",
        "# 정제된 결과를 10개만 확인해보죠\n",
        "corpus[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KontcjihyGqe",
        "outputId": "f74f6037-5893-4585-c1f1-a8a40a5476ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> is what i need <end>',\n",
              " '<start> come on <end>',\n",
              " '<start> but baby , <end>',\n",
              " '<start> i love you so , <end>',\n",
              " '<start> even though , <end>',\n",
              " '<start> let me tell you <end>',\n",
              " '<start> oh the power <end>',\n",
              " '<start> power of love <end>',\n",
              " '<start> ha yeah <end>',\n",
              " '<start> say love <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 평가 데이터셋 분리"
      ],
      "metadata": {
        "id": "Xxkx2VyT_Qkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "JnoDn2Hw_Te0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14000개의 단어가 들어갈 수 있는 tokenizer를 만든다. 앞서 이미 문장들을 정제했고, 만약 여기에 포함되지 않는 단어가 온다면 그것은 <unk> 로 바꾼다. 이 때 입력에 들어가는 문장들의 토큰 수는 모두 같아야한다. 따라서 이에 미치지 못하는 짧은 문장들은 패딩을 붙여 모두 같은 길이를 가지도록 한다. padding='pre' 이면 문장 앞에 패딩이 붙고, padding=<post> 이면 문장 뒤에 패딩이 붙는다."
      ],
      "metadata": {
        "id": "fh15olqznoJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(corpus):\n",
        "    # 14000단어를 기억할 수 있는 tokenizer를 만들겁니다\n",
        "    # 우리는 이미 문장을 정제했으니 filters가 필요없어요\n",
        "    # 14000단어에 포함되지 못한 단어는 '<unk>'로 바꿀거에요\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=14000, \n",
        "        filters=' ',\n",
        "        oov_token=\"<unk>\"\n",
        "    )\n",
        "    # corpus를 이용해 tokenizer 내부의 단어장을 완성합니다\n",
        "    # tokenizer.fit_on_texts(texts): 문자 데이터를 입력받아 리스트의 형태로 변환하는 메서드\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환합니다\n",
        "    # tokenizer.texts_to_sequences(texts): 텍스트 안의 단어들을 숫자의 시퀀스 형태로 변환하는 메서드\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춰줍니다\n",
        "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춰줍니다.\n",
        "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용합니다\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHrpIhMlyGoG",
        "outputId": "1f35a5bf-1523-478e-a367-9f20c1b068b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2  34  42 ...   0   0   0]\n",
            " [  2  36  21 ...   0   0   0]\n",
            " [  2  59  24 ...   0   0   0]\n",
            " ...\n",
            " [  2 210   3 ...   0   0   0]\n",
            " [  2 210   3 ...   0   0   0]\n",
            " [  2 210   3 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7fddb89f2a10>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tensor[:3, :10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aEvHSpPyGl7",
        "outputId": "e9003566-21e1-49a2-b88c-92dc820056cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2 34 42  4 87  3  0  0  0  0]\n",
            " [ 2 36 21  3  0  0  0  0  0  0]\n",
            " [ 2 59 24  5  3  0  0  0  0  0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.shape(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g73W4KnDjhU",
        "outputId": "d657e847-843f-4185-b3bc-20dbfe11d2ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14120, 13)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.index_word: 현재 계산된 단어의 인덱스와 인덱스에 해당하는 단어를 dictionary 형대로 반환 (Ex. {index: '~~', index: '~~', ...})\n",
        "for idx in tokenizer.index_word:\n",
        "    print(idx, \":\", tokenizer.index_word[idx])\n",
        "\n",
        "    if idx >= 10: break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zvDZb8WCqLY",
        "outputId": "efb58a9d-9131-4f0a-b777-abc6f7b3fc17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 : <unk>\n",
            "2 : <start>\n",
            "3 : <end>\n",
            "4 : i\n",
            "5 : ,\n",
            "6 : .\n",
            "7 : you\n",
            "8 : oh\n",
            "9 : it\n",
            "10 : me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 모든 문장이 인덱스 2로 시작하는 이유가 \\<start> 때문이다.  \n",
        "문장의 끝에 위치한 0은 사전에는 따로 나타나지 않지만 패딩 문자 \\<pad> 일 것이다.  "
      ],
      "metadata": {
        "id": "xvU_nDRVDUnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다\n",
        "# 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
        "src_input = tensor[:, :-1]  \n",
        "# tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
        "tgt_input = tensor[:, 1:]    \n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdEttFSFyGjj",
        "outputId": "8330d793-471b-4805-c9bb-720ef5c28ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 2 34 42  4 87  3  0  0  0  0  0  0]\n",
            "[34 42  4 87  3  0  0  0  0  0  0  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
        "                                                          tgt_input,\n",
        "                                                          test_size=0.2,\n",
        "                                                          shuffle=True, \n",
        "                                                          random_state=42)"
      ],
      "metadata": {
        "id": "6vtzewKHyGhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('enc_train:', enc_train.shape)\n",
        "print('dec_train:', dec_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S9HTXOQE1jG",
        "outputId": "b66c2840-1d67-43d0-89b9-ad4844063fce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enc_train: (11296, 12)\n",
            "dec_train: (11296, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(src_input)\n",
        "BATCH_SIZE = 256\n",
        "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
        "\n",
        "# tokenizer.num_words: 주어진 데이터의 문장들에서 빈도수가 높은 n개의 단어만 선택\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "# 준비한 데이터 소스로부터 데이터셋을 만듭니다\n",
        "# 데이터셋에 대해서는 아래 문서를 참고하세요\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CzX3pIsLxza",
        "outputId": "f82713bb-952b-4d31-ca61-b30ee2a1506a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(256, 12), dtype=tf.int32, name=None), TensorSpec(shape=(256, 12), dtype=tf.int32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 딥러닝 모델 설계 및 훈련"
      ],
      "metadata": {
        "id": "IVv5Flb8Kp1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy( \n",
        "    from_logits=True, reduction='none') # 클래스 분류 문제에서 softmax 함수를 거치면 from_logits = False(default값),그렇지 않으면 from_logits = True."
      ],
      "metadata": {
        "id": "6AgNDy0uKt3g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ],
      "metadata": {
        "id": "LLqB9JnRLHDS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        # Embedding 레이어, 2개의 LSTM 레이어, 1개의 Dense 레이어로 구성되어 있다.\n",
        "        # Embedding 레이어는 단어 사전의 인덱스 값을 해당 인덱스 번째의 워드 벡터로 바꿔준다.\n",
        "        # 이 워드 벡터는 의미 벡터 공간에서 단어의 추상적 표현으로 사용된다. \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size) \n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)  \n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "# embedding size 값이 커질수록 단어의 추상적인 특징들을 더 잡아낼 수 있지만\n",
        "# 그만큼 충분한 데이터가 없으면 안좋은 결과 값을 가져옵니다!   \n",
        "embedding_size = 256 # 워드 벡터의 차원수를 말하며 단어가 추상적으로 표현되는 크기입니다.\n",
        "hidden_size = 1024 # 모델에 얼마나 많은 일꾼을 둘 것인가? 정도로 이해하면 좋다.\n",
        "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size) # tokenizer.num_words에 +1인 이유는 문장에 없는 pad가 사용되었기 때문이다."
      ],
      "metadata": {
        "id": "kJXtUiesLKwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "# 한 배치만 불러온 데이터를 모델에 넣어봅니다\n",
        "lyricist(src_sample)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f46RCkfvLkW3",
        "outputId": "36dacc56-7e6b-44f3-8a3d-e6c7500be837"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(256, 12, 14001), dtype=float32, numpy=\n",
              "array([[[ 2.77788029e-04, -1.27151594e-04, -1.74182715e-04, ...,\n",
              "         -1.47247629e-04,  7.12201290e-05,  1.03006561e-04],\n",
              "        [ 3.08117509e-04,  6.41052102e-05, -2.66175572e-04, ...,\n",
              "         -1.14040879e-04,  2.15024469e-04,  1.75263587e-04],\n",
              "        [ 2.44525087e-04,  2.20720700e-04, -5.60876251e-05, ...,\n",
              "          7.37074733e-05,  3.34380195e-04,  2.79293803e-04],\n",
              "        ...,\n",
              "        [ 1.24193588e-03,  1.19125170e-05, -2.49085715e-04, ...,\n",
              "          7.36151182e-04, -2.76153628e-03, -6.38602942e-04],\n",
              "        [ 1.23954308e-03,  9.17265152e-06, -2.36481428e-04, ...,\n",
              "          9.19198093e-04, -3.17613897e-03, -7.18313735e-04],\n",
              "        [ 1.20552292e-03,  1.33618287e-05, -2.04468844e-04, ...,\n",
              "          1.11503259e-03, -3.54487752e-03, -7.79030670e-04]],\n",
              "\n",
              "       [[ 2.77788029e-04, -1.27151594e-04, -1.74182715e-04, ...,\n",
              "         -1.47247629e-04,  7.12201290e-05,  1.03006561e-04],\n",
              "        [ 4.73459688e-04, -3.33042153e-05, -7.78435860e-05, ...,\n",
              "         -9.71588452e-05,  8.13363804e-05,  2.10311904e-04],\n",
              "        [ 5.55646315e-04,  1.47861201e-05,  8.25297102e-05, ...,\n",
              "         -1.27578911e-04,  7.69198450e-05,  3.17504193e-04],\n",
              "        ...,\n",
              "        [ 1.35561568e-03,  2.53195558e-05, -5.97524422e-06, ...,\n",
              "          4.72588901e-04, -2.15976010e-03, -4.25614126e-04],\n",
              "        [ 1.38220866e-03,  2.82619203e-05, -5.17047811e-05, ...,\n",
              "          6.53948577e-04, -2.62670242e-03, -5.51998441e-04],\n",
              "        [ 1.37021462e-03,  3.75642339e-05, -6.99508601e-05, ...,\n",
              "          8.54501210e-04, -3.05712339e-03, -6.55125710e-04]],\n",
              "\n",
              "       [[ 2.77788029e-04, -1.27151594e-04, -1.74182715e-04, ...,\n",
              "         -1.47247629e-04,  7.12201290e-05,  1.03006561e-04],\n",
              "        [ 5.64637827e-04, -9.50193644e-05, -1.65779464e-04, ...,\n",
              "         -2.68354459e-04, -2.03835480e-05,  1.36354123e-04],\n",
              "        [ 8.59769701e-04, -2.06841360e-04, -2.29839261e-05, ...,\n",
              "         -3.12553369e-04, -8.38751512e-05,  1.16379597e-04],\n",
              "        ...,\n",
              "        [ 7.33248249e-04, -5.69499447e-04, -6.73538079e-06, ...,\n",
              "          4.62992146e-04, -1.49643689e-03, -4.58487106e-04],\n",
              "        [ 8.56033468e-04, -5.88000868e-04, -8.90001102e-05, ...,\n",
              "          5.69381285e-04, -2.01422186e-03, -6.29231450e-04],\n",
              "        [ 9.47520137e-04, -5.67282317e-04, -1.48487612e-04, ...,\n",
              "          7.00082921e-04, -2.50217528e-03, -7.67380232e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 2.77788029e-04, -1.27151594e-04, -1.74182715e-04, ...,\n",
              "         -1.47247629e-04,  7.12201290e-05,  1.03006561e-04],\n",
              "        [ 2.35629705e-04, -2.63174967e-04, -2.77220912e-04, ...,\n",
              "         -1.10056390e-04,  1.57547402e-04,  2.89673597e-04],\n",
              "        [ 9.89306718e-05, -2.27268843e-04, -6.68401044e-05, ...,\n",
              "          1.38610223e-04,  2.88979441e-04,  4.88865247e-04],\n",
              "        ...,\n",
              "        [ 9.64519917e-04, -6.79572186e-05, -8.36487452e-05, ...,\n",
              "          9.83629841e-04, -2.78896419e-03, -3.59857513e-04],\n",
              "        [ 9.84785613e-04, -3.00031334e-05, -6.59141151e-05, ...,\n",
              "          1.14650885e-03, -3.22113046e-03, -4.73072781e-04],\n",
              "        [ 9.76371753e-04,  5.22339587e-06, -3.47030073e-05, ...,\n",
              "          1.31965464e-03, -3.60549497e-03, -5.68016665e-04]],\n",
              "\n",
              "       [[ 2.77788029e-04, -1.27151594e-04, -1.74182715e-04, ...,\n",
              "         -1.47247629e-04,  7.12201290e-05,  1.03006561e-04],\n",
              "        [ 4.73459688e-04, -3.33042153e-05, -7.78435860e-05, ...,\n",
              "         -9.71588452e-05,  8.13363804e-05,  2.10311904e-04],\n",
              "        [ 4.86560195e-04,  1.34791626e-04,  1.79431503e-04, ...,\n",
              "          1.25781051e-04,  2.14739441e-04,  3.62212188e-04],\n",
              "        ...,\n",
              "        [ 1.42172410e-03,  1.36892850e-04, -2.18793837e-04, ...,\n",
              "          9.11160081e-04, -2.68137082e-03, -4.70261701e-04],\n",
              "        [ 1.40534947e-03,  1.27663938e-04, -2.19609996e-04, ...,\n",
              "          1.08651619e-03, -3.11590475e-03, -5.70381351e-04],\n",
              "        [ 1.35929929e-03,  1.21725738e-04, -1.97150279e-04, ...,\n",
              "          1.27201446e-03, -3.50648281e-03, -6.53059455e-04]],\n",
              "\n",
              "       [[ 2.77788029e-04, -1.27151594e-04, -1.74182715e-04, ...,\n",
              "         -1.47247629e-04,  7.12201290e-05,  1.03006561e-04],\n",
              "        [ 7.00927805e-04, -2.68277276e-04, -1.74162720e-04, ...,\n",
              "         -9.28891386e-05, -3.79692246e-05,  1.70522500e-04],\n",
              "        [ 7.98080757e-04, -2.33349521e-04,  6.11010037e-05, ...,\n",
              "          1.59758652e-04, -4.50731386e-06,  2.89647491e-04],\n",
              "        ...,\n",
              "        [ 1.53910078e-03, -1.69834515e-04, -2.03901553e-04, ...,\n",
              "          9.75486881e-04, -2.92660319e-03, -4.82925941e-04],\n",
              "        [ 1.49988174e-03, -1.37219264e-04, -1.97397647e-04, ...,\n",
              "          1.13902765e-03, -3.31627321e-03, -5.66073111e-04],\n",
              "        [ 1.43468042e-03, -1.03639846e-04, -1.70891974e-04, ...,\n",
              "          1.31307950e-03, -3.66322207e-03, -6.34432945e-04]]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lyricist.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8EFM0qLLa3o",
        "outputId": "cf695b3f-9532-4a67-c8a5-5925631989b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     multiple                  3584256   \n",
            "                                                                 \n",
            " lstm_10 (LSTM)              multiple                  5246976   \n",
            "                                                                 \n",
            " lstm_11 (LSTM)              multiple                  8392704   \n",
            "                                                                 \n",
            " dense_5 (Dense)             multiple                  14351025  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31,574,961\n",
            "Trainable params: 31,574,961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 아래 셀 실행 전 반드시 런타임 유형 변경할 것"
      ],
      "metadata": {
        "id": "iUlu_KCoU8rA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam() # Adam은 현재 가장 많이 사용하는 옵티마이저이다. 자세한 내용은 차차 배운다.\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
        "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
        "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
        ")\n",
        "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
        "lyricist.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
        "lyricist.fit(dataset, epochs=30, verbose=1) # 만들어둔 데이터셋으로 모델을 학습한다. 30번 학습을 반복하겠다는 의미다.\n",
        "\n",
        "# verbose = 1 이면 학습 과정을 간략하게 보여준다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceEKx3rSLa1U",
        "outputId": "e2c75a26-1fba-44cd-9a9c-543bb0007943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "55/55 [==============================] - 7s 85ms/step - loss: 2.8308\n",
            "Epoch 2/30\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.6788\n",
            "Epoch 3/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.4633\n",
            "Epoch 4/30\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.4000\n",
            "Epoch 5/30\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3705\n",
            "Epoch 6/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.3474\n",
            "Epoch 7/30\n",
            "55/55 [==============================] - 5s 87ms/step - loss: 1.3212\n",
            "Epoch 8/30\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2873\n",
            "Epoch 9/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.2637\n",
            "Epoch 10/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.3524\n",
            "Epoch 11/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.2311\n",
            "Epoch 12/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.2069\n",
            "Epoch 13/30\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.1859\n",
            "Epoch 14/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.1662\n",
            "Epoch 15/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.1487\n",
            "Epoch 16/30\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.1315\n",
            "Epoch 17/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.1153\n",
            "Epoch 18/30\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.1001\n",
            "Epoch 19/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.0842\n",
            "Epoch 20/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.0693\n",
            "Epoch 21/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.0547\n",
            "Epoch 22/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.0407\n",
            "Epoch 23/30\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.0267\n",
            "Epoch 24/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 1.0140\n",
            "Epoch 25/30\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.0007\n",
            "Epoch 26/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 0.9888\n",
            "Epoch 27/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 0.9737\n",
            "Epoch 28/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 0.9624\n",
            "Epoch 29/30\n",
            "55/55 [==============================] - 5s 86ms/step - loss: 0.9499\n",
            "Epoch 30/30\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 0.9386\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdd66af64d0>"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 딥러닝 평가하기"
      ],
      "metadata": {
        "id": "Sc6YdA7pcCcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adam"
      ],
      "metadata": {
        "id": "P6sAbS20GWhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#문장생성 함수 정의\n",
        "#모델에게 시작 문장을 전달하면 모델이 시작 문장을 바탕으로 작문을 진행\n",
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20): #시작 문자열을 init_sentence 로 받으며 디폴트값은 <start> 를 받는다\n",
        "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환합니다\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence]) #텍스트 안의 단어들을 숫자의 시퀀스의 형태로 변환\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    # 단어 하나씩 예측해 문장을 만듭니다\n",
        "    #    1. 입력받은 문장의 텐서를 입력합니다\n",
        "    #    2. 예측된 값 중 가장 높은 확률인 word index를 뽑아냅니다\n",
        "    #    3. 2에서 예측된 word index를 문장 뒤에 붙입니다\n",
        "    #    4. 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 마칩니다 (도달 하지 못하였으면 while 루프를 돌면서 다음 단어를 예측)\n",
        "    while True: #루프를 돌면서 init_sentence에 단어를 하나씩 생성성\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4 \n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizer를 이용해 word index를 단어로 하나씩 변환합니다 \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated #최종적으로 모델이 생성한 문장을 반환"
      ],
      "metadata": {
        "id": "Uxnup2XhcRms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)\n",
        "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
      ],
      "metadata": {
        "id": "6wDgzoI1cVOF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "11fc368b-f6ae-429f-b2c1-5acb254c8968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love you <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(lyricist, tokenizer, init_sentence=\"<start> i wanna\", max_len=20)\n",
        "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "I2CpB10ezOb7",
        "outputId": "ca7b4e16-55b8-4ec0-f149-8d4f9327b538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i wanna mingle <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSprop"
      ],
      "metadata": {
        "id": "-Bny8EbrGfAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "iKKkDd6ZGsln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다른 옵티마이저 사용\n",
        "# RMSprop\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop() \n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
        "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
        "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
        ")\n",
        "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
        "lyricist.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
        "lyricist.fit(dataset, epochs=30, verbose=1) # 만들어둔 데이터셋으로 모델을 학습한다. 30번 학습을 반복하겠다는 의미다.\n",
        "\n",
        "# verbose = 1 이면 학습 과정을 간략하게 보여준다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjpi3-fHwdE6",
        "outputId": "143cea77-bfc0-4386-873b-dd3c60fd9033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "55/55 [==============================] - 9s 88ms/step - loss: 2.2102\n",
            "Epoch 2/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 1.4654\n",
            "Epoch 3/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 1.3538\n",
            "Epoch 4/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 1.2893\n",
            "Epoch 5/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 1.2302\n",
            "Epoch 6/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 1.1798\n",
            "Epoch 7/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 1.1340\n",
            "Epoch 8/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 1.0958\n",
            "Epoch 9/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 1.0607\n",
            "Epoch 10/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 1.0279\n",
            "Epoch 11/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.9998\n",
            "Epoch 12/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.9735\n",
            "Epoch 13/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.9492\n",
            "Epoch 14/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.9284\n",
            "Epoch 15/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.9088\n",
            "Epoch 16/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.8907\n",
            "Epoch 17/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.8747\n",
            "Epoch 18/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.8602\n",
            "Epoch 19/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.8462\n",
            "Epoch 20/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.8347\n",
            "Epoch 21/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.8248\n",
            "Epoch 22/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.8144\n",
            "Epoch 23/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.8066\n",
            "Epoch 24/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.7989\n",
            "Epoch 25/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.7924\n",
            "Epoch 26/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.7859\n",
            "Epoch 27/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.7811\n",
            "Epoch 28/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.7755\n",
            "Epoch 29/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.7707\n",
            "Epoch 30/30\n",
            "55/55 [==============================] - 5s 88ms/step - loss: 0.7668\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdce3467990>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)\n",
        "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "po0JI7kLwc3M",
        "outputId": "bb1fa0f9-3e2d-4cd0-bb25-8fa33cf17474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love you <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(lyricist, tokenizer, init_sentence=\"<start> i wanna\", max_len=20)\n",
        "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "N4qjkvzsyZob",
        "outputId": "a25e093d-d448-475d-dfbc-e4215835cdbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i wanna do it <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adgrad"
      ],
      "metadata": {
        "id": "JC45Mm3tGiLB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lyricist = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
      ],
      "metadata": {
        "id": "xb9ICj_mGuHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다른 옵티마이저 사용\n",
        "# Adagrad\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adagrad() \n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
        "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
        "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
        ")\n",
        "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
        "lyricist.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
        "lyricist.fit(dataset, epochs=60, verbose=1) # 만들어둔 데이터셋으로 모델을 학습한다. 60번 학습을 반복하겠다는 의미다.\n",
        "\n",
        "# verbose = 1 이면 학습 과정을 간략하게 보여준다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLFHSB2hyZl4",
        "outputId": "740d1d74-3b6b-4e58-a81b-0cb8ef7bd37d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "55/55 [==============================] - 7s 85ms/step - loss: 1.4810\n",
            "Epoch 2/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3912\n",
            "Epoch 3/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3826\n",
            "Epoch 4/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3768\n",
            "Epoch 5/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3713\n",
            "Epoch 6/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3675\n",
            "Epoch 7/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3636\n",
            "Epoch 8/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3599\n",
            "Epoch 9/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3570\n",
            "Epoch 10/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3542\n",
            "Epoch 11/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3514\n",
            "Epoch 12/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3494\n",
            "Epoch 13/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3469\n",
            "Epoch 14/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3448\n",
            "Epoch 15/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3428\n",
            "Epoch 16/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3409\n",
            "Epoch 17/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3391\n",
            "Epoch 18/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3372\n",
            "Epoch 19/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3351\n",
            "Epoch 20/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3343\n",
            "Epoch 21/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3327\n",
            "Epoch 22/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3310\n",
            "Epoch 23/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3292\n",
            "Epoch 24/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3281\n",
            "Epoch 25/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3264\n",
            "Epoch 26/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3248\n",
            "Epoch 27/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3240\n",
            "Epoch 28/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3221\n",
            "Epoch 29/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3206\n",
            "Epoch 30/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3197\n",
            "Epoch 31/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3179\n",
            "Epoch 32/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3167\n",
            "Epoch 33/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3152\n",
            "Epoch 34/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3135\n",
            "Epoch 35/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3129\n",
            "Epoch 36/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3111\n",
            "Epoch 37/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3104\n",
            "Epoch 38/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3088\n",
            "Epoch 39/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3073\n",
            "Epoch 40/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3066\n",
            "Epoch 41/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3046\n",
            "Epoch 42/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3037\n",
            "Epoch 43/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3024\n",
            "Epoch 44/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.3018\n",
            "Epoch 45/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2997\n",
            "Epoch 46/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2991\n",
            "Epoch 47/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2981\n",
            "Epoch 48/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2968\n",
            "Epoch 49/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2957\n",
            "Epoch 50/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2943\n",
            "Epoch 51/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2927\n",
            "Epoch 52/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2923\n",
            "Epoch 53/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2914\n",
            "Epoch 54/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2901\n",
            "Epoch 55/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2892\n",
            "Epoch 56/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2877\n",
            "Epoch 57/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2874\n",
            "Epoch 58/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2860\n",
            "Epoch 59/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2850\n",
            "Epoch 60/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2843\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdce1c1be90>"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)\n",
        "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
      ],
      "metadata": {
        "id": "rPWacS4syZjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8cd67968-f1e6-4a9b-bd8d-ee5fd5a2eeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(lyricist, tokenizer, init_sentence=\"<start> i wanna\", max_len=20)\n",
        "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
      ],
      "metadata": {
        "id": "JkGGtDh5yZfA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bf908208-2f2d-4be4-b7d3-977eadf93e14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i wanna you <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adagrad\n",
        "# 60회 학습 추가 반복\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adagrad() \n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy( # 훈련 데이터의 라벨이 정수의 형태로 제공될 때 사용하는 손실함수이다.\n",
        "    from_logits=True, # 기본값은 False이다. 모델에 의해 생성된 출력 값이 정규화되지 않았음을 손실 함수에 알려준다. 즉 softmax함수가 적용되지 않았다는걸 의미한다. \n",
        "    reduction='none'  # 기본값은 SUM이다. 각자 나오는 값의 반환 원할 때 None을 사용한다.\n",
        ")\n",
        "# 모델을 학습시키키 위한 학습과정을 설정하는 단계이다.\n",
        "lyricist.compile(loss=loss, optimizer=optimizer) # 손실함수와 훈련과정을 설정했다.\n",
        "lyricist.fit(dataset, epochs=60, verbose=1) # 만들어둔 데이터셋으로 모델을 학습한다. 60번 학습을 반복하겠다는 의미다.\n",
        "\n",
        "# verbose = 1 이면 학습 과정을 간략하게 보여준다."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwO50L2PJ5oE",
        "outputId": "99a4a09e-43c4-4c0d-d441-377c0d565a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "55/55 [==============================] - 8s 85ms/step - loss: 1.4047\n",
            "Epoch 2/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2870\n",
            "Epoch 3/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2815\n",
            "Epoch 4/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2783\n",
            "Epoch 5/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2753\n",
            "Epoch 6/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2729\n",
            "Epoch 7/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2702\n",
            "Epoch 8/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2685\n",
            "Epoch 9/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2661\n",
            "Epoch 10/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2643\n",
            "Epoch 11/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2630\n",
            "Epoch 12/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2610\n",
            "Epoch 13/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2595\n",
            "Epoch 14/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2580\n",
            "Epoch 15/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2565\n",
            "Epoch 16/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2552\n",
            "Epoch 17/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2540\n",
            "Epoch 18/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2527\n",
            "Epoch 19/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2517\n",
            "Epoch 20/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2502\n",
            "Epoch 21/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2495\n",
            "Epoch 22/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2482\n",
            "Epoch 23/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2473\n",
            "Epoch 24/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2464\n",
            "Epoch 25/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2451\n",
            "Epoch 26/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2433\n",
            "Epoch 27/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2427\n",
            "Epoch 28/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2419\n",
            "Epoch 29/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2412\n",
            "Epoch 30/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2399\n",
            "Epoch 31/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2387\n",
            "Epoch 32/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2382\n",
            "Epoch 33/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2375\n",
            "Epoch 34/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2366\n",
            "Epoch 35/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2359\n",
            "Epoch 36/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2347\n",
            "Epoch 37/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2344\n",
            "Epoch 38/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2325\n",
            "Epoch 39/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2328\n",
            "Epoch 40/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2314\n",
            "Epoch 41/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2311\n",
            "Epoch 42/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2301\n",
            "Epoch 43/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2293\n",
            "Epoch 44/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2286\n",
            "Epoch 45/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2283\n",
            "Epoch 46/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2270\n",
            "Epoch 47/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2263\n",
            "Epoch 48/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2261\n",
            "Epoch 49/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2250\n",
            "Epoch 50/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2245\n",
            "Epoch 51/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2236\n",
            "Epoch 52/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2228\n",
            "Epoch 53/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2222\n",
            "Epoch 54/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2219\n",
            "Epoch 55/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2210\n",
            "Epoch 56/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2204\n",
            "Epoch 57/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2198\n",
            "Epoch 58/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2190\n",
            "Epoch 59/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2185\n",
            "Epoch 60/60\n",
            "55/55 [==============================] - 5s 85ms/step - loss: 1.2179\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdce21e1e50>"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(lyricist, tokenizer, init_sentence=\"<start> i love\", max_len=20)\n",
        "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lu2H08mkJ5g7",
        "outputId": "4d305afa-11bc-4d37-c02a-9c6c1c2bed6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i love you <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(lyricist, tokenizer, init_sentence=\"<start> i wanna\", max_len=20)\n",
        "# generate_text 함수에 lyricist 라 정의한 모델을 이용해서 ilove 로 시작되는 문장을 생성"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fFIRQTzjJ5Z0",
        "outputId": "6dc1fbd6-ca55-4d30-c26d-af8eb2708b23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<start> i wanna a da <end> '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 회고\n",
        "\n",
        "오늘은 자연어 처리를 이용해 주어진 단어들을 받으면 그에 이어서 자동으로 다음 단어를 추가하는 일을 했다. 자연어 처리는 우리가 일상적으로 사용하는 언어를 컴퓨터가 해석할 수 있도록 해야하므로 그것을 위한 데이터를 준비하는 것이 가장 중요하다.\n",
        "\n",
        "우선 내가 가진 데이터들을 전처리하는 작업이 필요하다. 이 때 불필요한 요소들과 문장들을 제거한다. 자연어의 특성상 수많은 데이터가 포함되어 있는데 이 때 불순물들을 걸러내지 못 한다면 딥러닝 모델의 목적을 달성하는 데에 방해가 될 수 있기 때문이다.\n",
        "\n",
        "그러고나면 기존에 존재하는 단어 사전을 가지고 각각의 단어들을 인덱스 토큰으로 바꿔준다. 단어 그 자체를 컴퓨터가 인식하는 것은 비효율적이므로 토큰으로 바꿔주고 레이어에 들어갈 수 있도록 모든 문장을 같은 수의 단어를 가지도록 한다. 짧은 문장에는 패딩 문자를 채워서 수를 통일하는 것이다. 이렇게 변환된 문장들을 embedding 레이어에 넣게 되면 각 단어들은 벡터화되어 여타 딥러닝 모델들과 마찬가지로 매개변수들을 학습하게 된다.\n",
        "\n",
        "여기서 중요한 것은 단어들을 벡터로 만든다는 것이다. 앞서 인덱스로 토큰화하긴 했으나 이 토큰들은 단어의 의미나, 단어 사이의 관계를 설명해주지 않는다. 따라서 단어의 의미를 여러 축을 가진 벡터들의 합으로 표현하는 것이다. 이렇게 한다면 그 뜻 뿐만 아니라 비슷한 단어들끼리 묶거나 유사한 단어들 간의 미묘한 차이를 포착하는 등 훨씬 더 정교한 작업을 할 수 있게 된다. 딥러닝은 바로 단어들의 벡터를 찾아내는 작업을 한다.\n",
        "\n",
        "이 때 모델에 optimizer가 존재하는데 이는 매개변수를 찾아가는 방식을 정의한다. 분명 같은 딥러닝 모델을 사용하더라도, 이 optimizer가 달라진다면 학습속도나 효율 그리고 결과물까지 달라질 수 있다. 일반적으로 Adam을 사용하지만 이번에는 RMSprop도 비슷하거나 더 나은 결과물을 (더 낮은 loss) 제공했으며 Adgrad는 점점 학습속도가 느려지는 특성상 다른 optimizer의 2배의 epoch을 진행했음에도 제대로 된 결과물이 나오지 않았다. 여기에 60회를 추가로 진행했을 때도 여전히 i wanna a da 라는 문장을 출력하며 불완전한 모습을 보였다.\n",
        "\n",
        "만약 나중에 자연어 처리 모델을 사용하게 된다면 필요와 상황에 맞게 optimizer를 사용해야만 빠른 속도와 좋은 결과물을 얻을 수 있을 것이다. 이 때 똑같이 학습이 잘 되었어도 결과물에는 작은 차이가 존재하기 때문에 각 특성을 미리 살펴보는 것이 중요하다고 할 수 있겠다.\n",
        "\n"
      ],
      "metadata": {
        "id": "SyeAmyhSqm2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reference\n",
        "\n",
        "https://blog.naver.com/gypsi12/222657990749 Tokenizer\n",
        "\n",
        "https://www.tensorflow.org/api_docs/python/tf/data/Dataset Dataset\n",
        "\n",
        "https://hwiyong.tistory.com/335 from_logits\n",
        "\n",
        "https://zzcojoa.tistory.com/108 Optimizers\n",
        "\n",
        "https://velog.io/@yookyungkho/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%98%B5%ED%8B%B0%EB%A7%88%EC%9D%B4%EC%A0%80-%EC%A0%95%EB%B3%B5%EA%B8%B0%EB%B6%80%EC%A0%9C-CS231n-Lecture7-Review Otimizers 2"
      ],
      "metadata": {
        "id": "wGg2CQSBHYXW"
      }
    }
  ]
}